---
---
有些场景，比如物联网，运维监控等，会不间断的产生海量的数据，这些数据就是时序数据。时序数据如下特点：
> 1. 时间递增
 2. 非结构数据
 3. 数据量大
 4. 写入后，很少更新
 5. 往往需要实时监控和分析

针对实时数据的这些特性，出现了很多时序数据库。**opentsdb**是其中一个。
![design]({{ site.url }}/assets/20171003/opentsdb.png)
opentsdb使用hbase存储数据，自然继承了hbase方便扩展、海量存储和超快读写的优势。

# 安装
### 环境准备
1. 需要jdk6或以上版本
2. 0.92或更新版本的HBase环境。为了方便，可以搭建一个伪分布式hadoop环境和一个伪分布式hbase环境。具体参考hadoop和hbase官网。
3. 4.2或者更新版本的gnuplot。gnuplot是一个交互式绘图工具，opentsdb管理界面的绘图功能使用了。

### 安装opentsdb
假设安装目录是/dir，首先进入/dir目录：

```cd /dir```

接下来下载opentsdb源码：

```git clone git://github.com/OpenTSDB/opentsdb.git```

然后编译源码：

```cd opentsdb
./build.sh```

如果编译成功，会出现一个**build**文件夹，里面包含**tsdb**脚本和**tsdb-2.3.0.jar**。

接下来修改src目录下的opentsdb.conf配置文件。其中比较重要的参数有：

> tsd.network.port 对外提供服务的端口号。一般填4242。
> tsd.http.staticroot 存放gui的静态文件的文件夹
  tsd.http.cachedir 存放缓存文件地址文件夹
  tsd.storage.hbase.zk_quorum hbase的zk地址
  tsd.core.auto_create_metrics 如果数据的度量标识不存在，是否自动创建度量标识的uid。改成true。

然后进入build文件夹:

```cd build```

如果是第一次使用opentsdb，首先需要在hbase中建立**tsdb**,**tsdb-uid**,**tsdb-meta**,**tsdb-tree**四个表，用来存储opentsdb数据。

```env COMPRESSION=NONE HBASE_HOME=path/to/hbase ../src/create_table.sh```

最后启动opentsdb

```./tsdb --config /dir/opentsdb/src/opentsdb.conf tsd```

启动日志会打印到控制台，可以看看有没有错误。
# 数据读写
opentsdb的数据包含四个字段：

**metric**：度量标识。比如记录cpu使用率的变化，可以使用"cpu.use"。

**timestamp**：数据时间戳。可以是秒，也可以是毫秒。

**value**：数据的值。可以是整型，长整型和浮点数。

**tag(s)**：标签。标签由tagk和tagv对组成。每个数据最少需要一对标签。

opentsdb提供http api和telnet api。其中http api比较普遍，下面操作使用http api。
### 写数据
接口地址：```/api/put```

http方法：post

数据体使用json格式。

下面下入一个数据：
```
curl -XPOST  '127.0.0.1:4242/api/put'  -d '
{
    "metric": "cpu.use",
    "timestamp": 1506981375167,
    "value": 66,
    "tags": {
        "host":"web01"
    }
}
`
```
也可以一次写入多个数据点：
```
curl -XPOST '127.0.0.1:4242/api/put' -d'
[
    {
        "metric":"cpu.use",
        "timestamp": 1506981377167,
        "value":67,
        "tags":{
            "host":"web01"
        }
    },
    {
        "metric":"cpu.use",
        "timestamp": 1506981379167,
        "value":68,
        "tags":{
            "host":"web01"
        }
    }
]
'
```
### 查询数据
接口地址：`/api/query`

方法：POST

参数说明：

下面是常用的几个参数：

|参数|含义|格式|是否必须|
|-----|-----|-----|-----|
|start|开始时间|可以是long型时间，也可以是"7d-ago"这种字符串|是|
|end|结束时间|同start格式|否|
|queries|查询语句|该参数可以包含多个子查询语句。每个子查询语句有三个参数：1.**metric**是度量标识 2.**aggregator**是聚合函数 3.**filters**是标签过滤器。|是|

<br/><br/>
下面查询**web01**服务器**cpu.use**近1天的数据，对同一个时间点的数据做求和操作:
```
curl -XPOST '127.0.0.1:4242/api/query' -d '
{
    "start":"1d-ago",
    "queries":[
        {
            "metric":"cpu.use",
            "aggregator":"sum",
            "filters":[
                {
                    "type":"literal_or",
                    "tagk":"host",
                    "filter":"web01",
                    "groupBy":false 
                }
            ]    
        }
    ]
}
'
```
结果如下：
```
[{"metric":"cpu.use","tags":{"host":"web01"},"aggregateTags":[],"dps":{"1506981375":66,"1506981377":67,"1506981379":68}}]
```
其中**dps**就是数据集合，每个key是数据的时间戳，value是数据的值。

### 下采样查询
考虑一种情况。一个温度传感器每秒中传送一次数据，那么一分钟是60个数据，一个小时3600个数据，一天是86400个点，一个星期是604800，这么大的数据量会带来一些问题。
> 1. 数据传输费流量，耗时间
2. 数据太多，做出来的图会乱

opentsdb提供了下采样查询处理这个问题。下采样查询需要两个主要元素：
> 1. 时间间隔。指定将多长时间内的数据做聚合。
2. 聚合函数。指明对数据做求和还是求平均等。

下面查询**web01**服务器**cpu.use**近1天的数据，数据按1个小时做下采样，聚合函数是平均值:
```
curl -XPOST '127.0.0.1:4242/api/query' -d '
{
    "start":"1d-ago",
    "queries":[
        {
            "metric":"cpu.use",
            "aggregator":"sum",
            "filters":[
                {
                    "type":"literal_or",
                    "tagk":"host",
                    "filter":"web01",
                    "groupBy":false 
                }
            ] ,
            "downsample":"1h-avg"
        }
    ]
}
'
```
结果返回了一个点，点的值是之前三个点的平均数：
```
[{"metric":"cpu.use","tags":{"host":"web01"},"aggregateTags":[],"dps":{"1506978000":67.0}}]
```

# opentsdb管理界面
在浏览器地址框输入:```127.0.0.1:4242```,就能进入opentsdb的管理界面。
![design]({{ site.url }}/assets/20171003/managedash1.png)
设置开始时间、度量标识、标签等参数，再选上自动加载和设置时间间隔，就能对数据做实时监控了。
![design]({{ site.url }}/assets/20171003/managedash2.png)


